{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3500, 400)\n",
      "(3500,)\n"
     ]
    }
   ],
   "source": [
    "# Reading the training data\n",
    "data_train = pd.read_csv('ex3_train.csv', sep=\",\", encoding='utf-8', header='infer')\n",
    "df_train = data_train\n",
    "\n",
    "y_train = df_train['y']\n",
    "X_train = df_train.drop(['y'], axis=1)\n",
    "# Adding one's column for bias\n",
    "# X_train.insert(0,-1,1) \n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7    0\n",
      "Name: y, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQgAAAD8CAYAAACLgjpEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSU0GhKQmA0JSkwEhqcmAkNRkQEhq+n9/PB80AymmYgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x105dc94d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reading the test data\n",
    "data_test = pd.read_csv('ex3_test.csv', sep=\",\", encoding='utf-8', header='infer')\n",
    "df_test = data_test\n",
    "\n",
    "y_test = df_test['y']\n",
    "X_test = df_test.drop(['y'], axis=1)\n",
    "\n",
    "#Plot the selected pixel\n",
    "num = 7\n",
    "pixels = np.array(X_test[num:num+1], dtype='uint8')\n",
    "print(y_test[num:num+1])\n",
    "pixels = pixels.reshape((20, 20))\n",
    "plt.imshow(pixels, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Adding one's column for bias\n",
    "# X_test.insert(0,-1,1) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Defining Hyperparameters\n",
    "inputLayerSize = X_train.shape[1]\n",
    "hiddenLayerSize = 25 # As specified in assignment requirements\n",
    "outputLayerSize = y_train_mat.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3500, 10)\n"
     ]
    }
   ],
   "source": [
    "# One hot Encoding the categorical output values to binary by adding 1's for that index and 0's otherwise\n",
    "def oneHotEncode(y):\n",
    "    enc = pd.get_dummies(y)\n",
    "    return np.matrix(enc)\n",
    "\n",
    "y_train_mat = oneHotEncode(y_train)\n",
    "print(y_train_mat.shape)\n",
    "\n",
    "\n",
    "# Applying Sigmoid Activation function to the hidden layer outputs, works with scalar, arrays and matrix as well\n",
    "# Purpose of this method is to do squishing on the linear function\n",
    "def apply_sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))\n",
    "\n",
    "\n",
    "# Forward propagation to calculate yHat by applying activation function twice\n",
    "def forward_propagate(X, W1):\n",
    "    z2 = np.dot(X, W1)\n",
    "    print('z2 shape---')\n",
    "    print(z2.shape)\n",
    "    a2 = apply_sigmoid(z2)\n",
    "    print('a2 shape---')\n",
    "    print(a2.shape)\n",
    "    print(z2)\n",
    "    W2 = 0.01* np.random.randn(hiddenLayerSize,outputLayerSize);\n",
    "#     W2_bias = np.c_[np.ones((W2.shape[0], 1)), W2] # Add column for bias\n",
    "    z3 = np.dot(a2, W2)\n",
    "    yHat = apply_sigmoid(z3) # Output of the last layer(output layer)\n",
    "    return yHat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n",
      "10\n",
      "25\n",
      "(400, 25)\n",
      "(401, 26)\n",
      "[[-0.00260622 -0.01250191 -0.00178242 ...,  0.00632297 -0.00968918\n",
      "   0.00617907]\n",
      " [ 0.00936864 -0.00170305  0.00631742 ...,  0.00582405 -0.00108779\n",
      "   0.01443415]\n",
      " [ 0.01369773 -0.0054706   0.00050398 ...,  0.0081098  -0.00049111\n",
      "  -0.00166223]\n",
      " ..., \n",
      " [ 0.00200798  0.00364304 -0.01407197 ...,  0.00351922 -0.01501257\n",
      "  -0.00030978]\n",
      " [ 0.00142657  0.00471447 -0.00940441 ..., -0.0037205   0.00363001\n",
      "  -0.00739288]\n",
      " [ 0.00607796  0.00633714  0.00295091 ...,  0.00779166  0.00590219\n",
      "   0.00463926]]\n",
      "[[  1.00000000e+00  -8.83746902e-03  -6.77017123e-03 ...,  -6.41417353e-03\n",
      "   -1.28484599e-02  -1.05394168e-02]\n",
      " [  1.00000000e+00   1.83739851e-02   6.03630333e-03 ...,   1.68747849e-02\n",
      "    3.01187128e-03  -6.39488640e-03]\n",
      " [  1.00000000e+00   7.01669824e-03   2.23688794e-05 ...,  -1.61131523e-02\n",
      "    1.48364547e-02   2.40776779e-03]\n",
      " ..., \n",
      " [  1.00000000e+00  -9.08313083e-03  -2.19351685e-03 ...,   1.34693919e-02\n",
      "   -1.09775967e-02   2.49741339e-03]\n",
      " [  1.00000000e+00  -6.99241603e-03  -2.99642135e-03 ...,   7.07260492e-03\n",
      "   -7.77447831e-03   4.59344159e-03]\n",
      " [  1.00000000e+00   4.68555195e-03  -3.77500880e-03 ...,   1.13110427e-02\n",
      "   -9.97787407e-03  -2.25721762e-03]]\n",
      "z2 shape---\n",
      "(3500, 25)\n",
      "a2 shape---\n",
      "(3500, 25)\n",
      "[[-0.03158779  0.01839274  0.00214988 ...,  0.06479837 -0.01516742\n",
      "  -0.04869455]\n",
      " [-0.09098218 -0.03914355 -0.01242945 ...,  0.08425659  0.06845419\n",
      "  -0.04245332]\n",
      " [-0.00791389 -0.04596565  0.06622075 ...,  0.10772279  0.06174055\n",
      "  -0.05479368]\n",
      " ..., \n",
      " [-0.1108577  -0.00382595 -0.02888109 ...,  0.04342592  0.10666588\n",
      "  -0.04493557]\n",
      " [-0.01972548  0.0028475   0.00859883 ...,  0.07489993  0.02959668\n",
      "  -0.06220866]\n",
      " [-0.14649114 -0.00299146  0.07828864 ...,  0.11982251  0.04985636\n",
      "  -0.03338868]]\n",
      "[[ 0.49575602  0.5071827   0.49866436 ...,  0.49831393  0.50434046\n",
      "   0.49856421]\n",
      " [ 0.49579327  0.50705013  0.49851582 ...,  0.49848642  0.50435686\n",
      "   0.49840069]\n",
      " [ 0.49577045  0.50723855  0.49867026 ...,  0.49824007  0.50435435\n",
      "   0.49814526]\n",
      " ..., \n",
      " [ 0.49561507  0.50720546  0.49846818 ...,  0.49817892  0.50433741\n",
      "   0.49827092]\n",
      " [ 0.49578974  0.50722259  0.49859625 ...,  0.49848213  0.50442289\n",
      "   0.49845215]\n",
      " [ 0.49577174  0.50733304  0.49867841 ...,  0.49820685  0.50429277\n",
      "   0.49821283]]\n",
      "(3500, 10)\n"
     ]
    }
   ],
   "source": [
    "print(inputLayerSize)\n",
    "print(outputLayerSize)\n",
    "print(hiddenLayerSize)\n",
    "\n",
    "# Call Forward propagation to calculate yHat\n",
    "W1 = 0.01* np.random.randn(inputLayerSize,hiddenLayerSize);\n",
    "# W1_bias = np.c_[np.ones((W1.shape[0], 1)), W1] # Add column for bias\n",
    "\n",
    "print(W1.shape);\n",
    "print(W1_bias.shape);\n",
    "print(W1);\n",
    "print(W1_bias);\n",
    "y_train_Hat = forward_propagate(X_train, W1)\n",
    "print(y_train_Hat)\n",
    "print(y_train_Hat.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
