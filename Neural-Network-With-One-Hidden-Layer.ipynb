{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "np.random.seed(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot Encoding the categorical output values to binary by adding 1's for that index and 0's otherwise\n",
    "def oneHotEncode(y):\n",
    "#     print('Before Encoding ')\n",
    "#     print(y)\n",
    "#     print(type(y))\n",
    "    enc = pd.get_dummies(y['y'])\n",
    "#     print('After Encoding ')\n",
    "#     print(enc)\n",
    "    return np.matrix(enc)\n",
    "\n",
    "# Applying Sigmoid Activation function to the hidden layer outputs used while forward propagation\n",
    "# works with scalar, arrays and matrix as well\n",
    "# Purpose of this method is to do squishing on the linear function\n",
    "def apply_sigmoid(z):\n",
    "    return 1./(1.+np.exp(-z))\n",
    "\n",
    "# Applying Sigmoid Activation function to the hidden layer outputs used while backward propagation to get gradients\n",
    "# works with scalar, arrays and matrix as well\n",
    "# Purpose of this method is to do undo the squishing on the linear function\n",
    "def apply_sigmoid_prime(z):\n",
    "    print('Before')\n",
    "    print(z)\n",
    "    inv = np.multiply(z, (1-z))\n",
    "    print('After')\n",
    "    print(inv)\n",
    "    return inv\n",
    "\n",
    "\n",
    "# Forward propagation to calculate yHat by applying activation function twice\n",
    "def forward_propagate(X, W1, W2, b1, b2):\n",
    "    Z1 = np.dot(W1.T, X) + b1\n",
    "#     print('----Z1----')\n",
    "#     print(Z1)\n",
    "    A1 = apply_sigmoid(Z1)\n",
    "#     print('----A1----')\n",
    "#     print(A1)\n",
    "    Z2 = np.dot(W2.T, A1) + b2\n",
    "#     print('----Z2----')\n",
    "#     print(Z2)\n",
    "    A2 = apply_sigmoid(Z2) # Output of the last layer(output layer)\n",
    "#     print('----A2----')\n",
    "#     print(A2)\n",
    "    return A1, A2, Z1, Z2\n",
    "\n",
    "# Backward Propagation function to calculate the gradients\n",
    "def back_propagate(Z1, X, Y, A1, A2, W2):\n",
    "    m = X.shape[1]\n",
    "#     print(m)\n",
    "#     print('----Y----')\n",
    "#     print(Y)\n",
    "#     print('----A2----')\n",
    "#     print(A2)\n",
    "    dZ2 = (A2 - Y);\n",
    "#     print('----dz2----')\n",
    "#     print(dZ2)\n",
    "#     print(type(dZ2))\n",
    "#     print('----A1T----')\n",
    "#     print(A1.T)\n",
    "    dW2 = (1./m) * np.dot(dZ2, A1.T)\n",
    "    print('----dw2----')\n",
    "    print(dW2)\n",
    "    db2 = (1./m) * np.sum(dZ2, axis=1)\n",
    "    print('----db2----')\n",
    "    print(db2)\n",
    "    temp1 = np.dot( W2, dZ2 )\n",
    "    temp2 = apply_sigmoid_prime(Z1)\n",
    "#     print(temp1.shape)\n",
    "#     print(temp2.shape)\n",
    "    dZ1 = np.multiply(temp1 , temp2) # element wise product of same dimension matrices\n",
    "#     print('----dz1----')\n",
    "#     print(dZ1)\n",
    "    dW1 = (1./m) * np.dot(dZ1, X.T)\n",
    "    print('----dw1----')\n",
    "    print(dW1)\n",
    "    db1 = (1./m) * np.sum(dZ1, axis =1)\n",
    "    print('----db1----')\n",
    "    print(db1)\n",
    "    return dW1, db1, dW2, db2\n",
    "    \n",
    "# Get the loss of for the training example\n",
    "def get_cost(Y, Yhat):\n",
    "    m= Y.shape[1]\n",
    "#     print(m)\n",
    "    loss = np.multiply(np.log(Yhat),Y) + np.multiply((1-Y), np.log(1 - Yhat))\n",
    "#     print(loss)\n",
    "    cost = (-1/m) * np.sum(loss)\n",
    "    cost = np.squeeze(cost)\n",
    "    return cost\n",
    "\n",
    "def gradientDescent(X, Y, alpha, iters):  \n",
    "    # Call Forward propagation to calculate yHat\n",
    "    W1 = 0.01* np.random.randn(inputLayerSize,hiddenLayerSize);\n",
    "    W2 = 0.01* np.random.randn(hiddenLayerSize,outputLayerSize);\n",
    "    b1 = np.zeros((hiddenLayerSize,1));\n",
    "    b2 = np.zeros((outputLayerSize,1));\n",
    "    old_cost = sys.maxsize\n",
    "    new_cost = sys.maxsize\n",
    "    dW1 = None\n",
    "    db1 = None\n",
    "    dW2 = None\n",
    "    db2 = None\n",
    "    cost_history = []\n",
    "    for i in range(iters):\n",
    "        A1, A2, Z1, Z2 = forward_propagate(X, W1, W2, b1, b2)\n",
    "        dW1, db1, dW2, db2 = back_propagate(Z1, X, Y, A1, A2, W2)\n",
    "        temp = (alpha * dW1.T)\n",
    "        print(temp)\n",
    "        W1 = W1 - temp\n",
    "        print('After')\n",
    "        print(W1)\n",
    "        b1 = b1 - (alpha * db1)\n",
    "        W2 = W2 - (alpha * dW2.T)\n",
    "        b2 = b2 - (alpha * db2)\n",
    "        old_cost = new_cost\n",
    "        new_cost = get_cost(Y, A2)\n",
    "        if(abs(old_cost - new_cost) < 0.00001):\n",
    "            print(\"breaking\" + str(old_cost) + str(new_cost))\n",
    "            break;\n",
    "        print (\"cost : \" + str(new_cost) + \" Old cost : \" + str(old_cost) + \" Iteration: \" + str(i))\n",
    "        cost_history.append(new_cost)\n",
    "    return W1 , b1, W2, b2, cost_history, new_cost\n",
    "\n",
    "# Softmax activation function to get the probablity of the classes\n",
    "def softmax(z):\n",
    "    softMax = (np.exp(z).T / np.sum(np.exp(z),axis=1)).T\n",
    "    print('softmax is ')\n",
    "    print(softMax)\n",
    "    return softMax\n",
    "\n",
    "def plotCostHistory(cost_history):\n",
    "     plt.plot(cost_history)\n",
    "     plt.ylabel('Cost');\n",
    "     plt.xlabel('Iterations');\n",
    "     plt.title('Cost Progression with Iterations for different learning rates')\n",
    "     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Reading the training data\n",
    "data_train = pd.read_csv('ex3_train.csv', sep=\",\", encoding='utf-8', header='infer')\n",
    "df_train = data_train\n",
    "m = df_train.shape[0]\n",
    "\n",
    "y_train = pd.DataFrame(df_train['y'])\n",
    "X_train = df_train.drop(['y'], axis=1)\n",
    "\n",
    "X_train_mat = np.matrix(X_train).T\n",
    "y_train_mat = oneHotEncode(y_train).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the test data\n",
    "data_test = pd.read_csv('ex3_test.csv', sep=\",\", encoding='utf-8', header='infer')\n",
    "df_test = data_test\n",
    "\n",
    "y_test = df_test['y']\n",
    "X_test = df_test.drop(['y'], axis=1)\n",
    "\n",
    "X_test_mat = np.matrix(X_test).T\n",
    "y_test_mat = np.matrix(y_test)\n",
    "\n",
    "# print(X_test_mat.shape)\n",
    "# print(y_test_mat.shape)\n",
    "\n",
    "#Plot the selected pixel\n",
    "# num = 7\n",
    "# pixels = np.array(X_test[num:num+1], dtype='uint8')\n",
    "# print(y_test[num:num+1])\n",
    "# pixels = pixels.reshape((20, 20))\n",
    "# plt.imshow(pixels, cmap='gray')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# Adding one's column for bias\n",
    "# X_test.insert(0,-1,1) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n",
      "10\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "# Defining Hyperparameters\n",
    "inputLayerSize = X_train_mat.shape[0]\n",
    "hiddenLayerSize = 25 # As specified in assignment requirements\n",
    "outputLayerSize = 10\n",
    "print(inputLayerSize)\n",
    "print(outputLayerSize)\n",
    "print(hiddenLayerSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization function to check cost propagartion for different learning rates\n",
    "\n",
    "def optimize():\n",
    "    alpha = [0.1]\n",
    "    for a in alpha:\n",
    "        W1 , b1, W2, b2, cost_history, new_cost = gradientDescent(X_train_mat, y_train_mat, a, 6000)\n",
    "        plotCostHistory(cost_history)\n",
    "        return W1 , b1, W2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----dw2----\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.]]\n",
      "----db2----\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "Before\n",
      "[[ 0.03530912 -0.00949417 -0.05612952 ...,  0.00259634  0.01701968\n",
      "  -0.08637879]\n",
      " [ 0.07757273  0.04442737  0.08868166 ...,  0.02343571  0.06219907\n",
      "   0.06908766]\n",
      " [ 0.02654129 -0.0665131  -0.09437684 ...,  0.06191418  0.00919515\n",
      "   0.05590712]\n",
      " ..., \n",
      " [ 0.06942794  0.19161338  0.05524448 ...,  0.01619004  0.10375813\n",
      "   0.00130557]\n",
      " [-0.02340018 -0.07069389  0.03136635 ...,  0.08619377  0.06198716\n",
      "   0.0165347 ]\n",
      " [ 0.01999674  0.00662632  0.05485955 ..., -0.14580055 -0.04281674\n",
      "  -0.18518303]]\n",
      "After\n",
      "[[ 0.03406238 -0.00958431 -0.05928004 ...,  0.0025896   0.01673001\n",
      "  -0.09384009]\n",
      " [ 0.0715552   0.04245358  0.08081722 ...,  0.02288648  0.05833034\n",
      "   0.06431455]\n",
      " [ 0.02583685 -0.07093709 -0.10328383 ...,  0.05808082  0.0091106\n",
      "   0.05278151]\n",
      " ..., \n",
      " [ 0.0646077   0.15489769  0.05219253 ...,  0.01592792  0.09299238\n",
      "   0.00130386]\n",
      " [-0.02394775 -0.07569151  0.0303825  ...,  0.0787644   0.05814475\n",
      "   0.0162613 ]\n",
      " [ 0.01959687  0.00658241  0.05184998 ..., -0.16705835 -0.04465001\n",
      "  -0.21947579]]\n",
      "----dw1----\n",
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "----db1----\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "After\n",
      "[[ 0.01624345 -0.00611756 -0.00528172 ...,  0.00901591  0.00502494\n",
      "   0.00900856]\n",
      " [-0.00683728 -0.0012289  -0.00935769 ...,  0.02100255  0.00120159\n",
      "   0.00617203]\n",
      " [ 0.0030017  -0.0035225  -0.01142518 ...,  0.00160037  0.00876169\n",
      "   0.00315635]\n",
      " ..., \n",
      " [ 0.01633164 -0.00240168  0.01274305 ..., -0.01343476  0.00796549\n",
      "  -0.00277811]\n",
      " [ 0.00364705  0.00482789  0.00036578 ...,  0.00907937 -0.0054449\n",
      "   0.00333512]\n",
      " [-0.0012146  -0.01120876 -0.0040898  ..., -0.01014144 -0.00062696\n",
      "  -0.0143787 ]]\n",
      "cost : 24398.5138857 Old cost : 9223372036854775807 Iteration: 0\n",
      "----dw2----\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.]]\n",
      "----db2----\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "Before\n",
      "[[ 0.03530912 -0.00949417 -0.05612952 ...,  0.00259634  0.01701968\n",
      "  -0.08637879]\n",
      " [ 0.07757273  0.04442737  0.08868166 ...,  0.02343571  0.06219907\n",
      "   0.06908766]\n",
      " [ 0.02654129 -0.0665131  -0.09437684 ...,  0.06191418  0.00919515\n",
      "   0.05590712]\n",
      " ..., \n",
      " [ 0.06942794  0.19161338  0.05524448 ...,  0.01619004  0.10375813\n",
      "   0.00130557]\n",
      " [-0.02340018 -0.07069389  0.03136635 ...,  0.08619377  0.06198716\n",
      "   0.0165347 ]\n",
      " [ 0.01999674  0.00662632  0.05485955 ..., -0.14580055 -0.04281674\n",
      "  -0.18518303]]\n",
      "After\n",
      "[[ 0.03406238 -0.00958431 -0.05928004 ...,  0.0025896   0.01673001\n",
      "  -0.09384009]\n",
      " [ 0.0715552   0.04245358  0.08081722 ...,  0.02288648  0.05833034\n",
      "   0.06431455]\n",
      " [ 0.02583685 -0.07093709 -0.10328383 ...,  0.05808082  0.0091106\n",
      "   0.05278151]\n",
      " ..., \n",
      " [ 0.0646077   0.15489769  0.05219253 ...,  0.01592792  0.09299238\n",
      "   0.00130386]\n",
      " [-0.02394775 -0.07569151  0.0303825  ...,  0.0787644   0.05814475\n",
      "   0.0162613 ]\n",
      " [ 0.01959687  0.00658241  0.05184998 ..., -0.16705835 -0.04465001\n",
      "  -0.21947579]]\n",
      "----dw1----\n",
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "----db1----\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "After\n",
      "[[ 0.01624345 -0.00611756 -0.00528172 ...,  0.00901591  0.00502494\n",
      "   0.00900856]\n",
      " [-0.00683728 -0.0012289  -0.00935769 ...,  0.02100255  0.00120159\n",
      "   0.00617203]\n",
      " [ 0.0030017  -0.0035225  -0.01142518 ...,  0.00160037  0.00876169\n",
      "   0.00315635]\n",
      " ..., \n",
      " [ 0.01633164 -0.00240168  0.01274305 ..., -0.01343476  0.00796549\n",
      "  -0.00277811]\n",
      " [ 0.00364705  0.00482789  0.00036578 ...,  0.00907937 -0.0054449\n",
      "   0.00333512]\n",
      " [-0.0012146  -0.01120876 -0.0040898  ..., -0.01014144 -0.00062696\n",
      "  -0.0143787 ]]\n",
      "breaking24398.513885724398.5138857\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZwAAAEWCAYAAABSaiGHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110661ed0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(matrix([[ 0.01624345, -0.00611756, -0.00528172, ...,  0.00901591,\n",
       "           0.00502494,  0.00900856],\n",
       "         [-0.00683728, -0.0012289 , -0.00935769, ...,  0.02100255,\n",
       "           0.00120159,  0.00617203],\n",
       "         [ 0.0030017 , -0.0035225 , -0.01142518, ...,  0.00160037,\n",
       "           0.00876169,  0.00315635],\n",
       "         ..., \n",
       "         [ 0.01633164, -0.00240168,  0.01274305, ..., -0.01343476,\n",
       "           0.00796549, -0.00277811],\n",
       "         [ 0.00364705,  0.00482789,  0.00036578, ...,  0.00907937,\n",
       "          -0.0054449 ,  0.00333512],\n",
       "         [-0.0012146 , -0.01120876, -0.0040898 , ..., -0.01014144,\n",
       "          -0.00062696, -0.0143787 ]]), matrix([[ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.]]), matrix([[ -1.22473906e-03,   2.28169819e-03,  -3.52305130e-03,\n",
       "           -8.30553443e-03,  -2.61089816e-03,   1.69354228e-03,\n",
       "            6.73623098e-03,  -3.27201605e-03,  -3.05299147e-03,\n",
       "            5.24865332e-03],\n",
       "         [ -5.84186924e-03,  -2.27752272e-03,  -5.32907034e-03,\n",
       "           -8.00368058e-03,   1.02965151e-02,  -6.59722144e-03,\n",
       "           -4.61377449e-04,   2.11514027e-03,  -6.28114509e-03,\n",
       "            6.11307618e-03],\n",
       "         [  4.68166044e-03,   7.94645859e-03,   4.70312714e-03,\n",
       "            8.94125528e-03,   1.51991551e-02,  -1.79079179e-02,\n",
       "            1.08809245e-02,   1.51684632e-02,   1.49886029e-03,\n",
       "            1.06126568e-02],\n",
       "         [ -3.84317098e-03,   1.11118963e-02,  -8.31650678e-03,\n",
       "           -4.52408931e-03,   3.86806022e-03,   1.91860898e-03,\n",
       "            8.91496105e-05,  -1.73634985e-02,  -1.25180062e-02,\n",
       "           -6.46216406e-03],\n",
       "         [ -9.06922534e-03,   7.91953386e-03,  -1.29740188e-02,\n",
       "            2.52544296e-03,  -1.06721258e-02,  -5.99677700e-03,\n",
       "           -1.27136074e-02,  -9.68803098e-03,  -6.12326249e-03,\n",
       "            1.47859115e-02],\n",
       "         [  2.85285322e-03,  -1.59786438e-02,  -1.06045205e-02,\n",
       "           -1.99962342e-03,  -2.41028034e-03,   3.86644182e-03,\n",
       "            8.74035272e-03,  -3.44320973e-03,  -1.14690355e-02,\n",
       "           -1.09322779e-02],\n",
       "         [  2.12748670e-03,   1.00451584e-02,  -9.01591332e-03,\n",
       "           -5.85845897e-03,   2.91781118e-03,   2.63774755e-03,\n",
       "           -9.09136630e-03,   1.16096904e-02,   1.06024539e-02,\n",
       "            1.91671613e-02],\n",
       "         [ -4.62677701e-03,  -1.86426200e-04,  -1.56149217e-02,\n",
       "            1.21248591e-03,  -5.97463652e-03,  -4.48582043e-04,\n",
       "            4.96154454e-03,  -7.08052399e-04,   1.06505995e-02,\n",
       "            5.78661240e-03],\n",
       "         [ -8.25800027e-03,  -5.18017376e-03,  -4.81854823e-03,\n",
       "           -2.10123491e-03,   2.38427478e-02,   6.11553861e-03,\n",
       "           -6.73413646e-03,  -3.25054863e-03,   7.51856098e-03,\n",
       "           -1.42172933e-03],\n",
       "         [ -1.44094639e-02,   1.82519863e-02,   4.37100049e-03,\n",
       "           -5.27999518e-03,  -5.33271917e-03,  -3.98500469e-03,\n",
       "            3.64631892e-03,  -1.57170263e-03,   5.38650812e-03,\n",
       "            9.75631159e-03],\n",
       "         [ -1.46105588e-02,   1.47477860e-02,   1.20373449e-02,\n",
       "            7.32616389e-03,   8.44207978e-03,   9.11947964e-03,\n",
       "            1.47609455e-02,  -1.49130206e-02,  -9.62285800e-03,\n",
       "           -1.65972412e-02],\n",
       "         [  1.54952997e-02,  -2.43675607e-03,   9.73238295e-03,\n",
       "            2.48259601e-03,  -8.09740519e-03,  -2.30583044e-03,\n",
       "            7.06110608e-04,  -5.86429557e-04,   1.17084940e-03,\n",
       "            7.89749152e-03],\n",
       "         [  2.67220487e-03,   5.68878118e-03,   7.10935577e-03,\n",
       "            1.01859938e-02,   1.60106152e-02,  -1.30479815e-02,\n",
       "            3.48218921e-04,   7.70946262e-03,  -5.47709618e-03,\n",
       "           -9.14895431e-03],\n",
       "         [  2.02669157e-03,   1.32662103e-02,   1.85066247e-02,\n",
       "           -2.25998374e-02,  -1.22860668e-02,  -5.53391257e-03,\n",
       "            6.44858149e-03,  -4.15984757e-04,  -2.32049503e-03,\n",
       "            7.11362219e-04],\n",
       "         [  1.52691100e-04,   1.54133592e-02,   3.02726792e-04,\n",
       "            1.44291992e-02,  -1.39798532e-02,   7.31191586e-03,\n",
       "           -2.79944124e-03,  -3.02291438e-04,   1.51009906e-02,\n",
       "           -1.38387039e-02],\n",
       "         [  8.61512971e-03,  -1.17035753e-02,   2.00105064e-02,\n",
       "           -3.19479230e-03,   5.45804889e-03,   1.21286736e-02,\n",
       "            1.72120361e-03,   8.22203059e-04,  -1.42682815e-02,\n",
       "            2.05442192e-02],\n",
       "         [  1.89926564e-03,  -1.38520037e-03,   6.20142899e-03,\n",
       "            1.65813170e-02,  -1.86460059e-03,   9.19220098e-03,\n",
       "            2.39325768e-05,   8.59368744e-03,  -1.09919872e-02,\n",
       "            1.46592679e-02],\n",
       "         [  4.70481419e-03,   7.18918899e-03,   1.31938016e-02,\n",
       "            4.76753246e-04,   7.54169945e-03,   3.25137969e-03,\n",
       "           -1.50380575e-02,   1.15085038e-02,  -4.08525627e-03,\n",
       "           -2.04512338e-02],\n",
       "         [ -7.28757140e-04,   1.34194019e-02,   1.05705951e-02,\n",
       "           -1.38770279e-02,   2.52593533e-03,   1.09925705e-02,\n",
       "            7.46178657e-03,   3.72390073e-03,  -1.85749619e-02,\n",
       "            8.33959618e-03],\n",
       "         [ -4.22625640e-04,   1.48629738e-02,   3.26005886e-03,\n",
       "            1.30370710e-02,   7.26861507e-03,  -1.10633774e-02,\n",
       "            1.49055510e-02,   1.23677626e-03,  -1.78190805e-02,\n",
       "            4.36259060e-03],\n",
       "         [ -4.74864572e-03,   9.24238808e-03,   7.46216287e-03,\n",
       "           -2.92820328e-03,   5.17689046e-03,   1.85065792e-03,\n",
       "            1.38907452e-02,   6.47942929e-03,  -8.17494070e-03,\n",
       "           -7.50450505e-03],\n",
       "         [ -1.84290827e-02,  -1.07132832e-02,   1.36280689e-02,\n",
       "           -7.55542289e-03,   3.15221339e-03,   1.99434230e-02,\n",
       "           -1.07306424e-02,  -4.63248286e-03,   1.33610507e-02,\n",
       "           -2.54552211e-03],\n",
       "         [  7.94711547e-03,  -2.93319287e-03,  -5.33957726e-03,\n",
       "           -1.06903468e-02,   5.74600419e-03,  -1.04957664e-02,\n",
       "           -2.50641071e-04,   6.94079032e-04,   4.28065662e-04,\n",
       "           -5.67480893e-03],\n",
       "         [ -9.00783784e-04,   9.04964799e-03,  -8.82975691e-03,\n",
       "           -9.06215012e-03,  -1.49068097e-02,  -1.33213202e-03,\n",
       "           -3.40662254e-03,   3.37891717e-03,   7.90900703e-03,\n",
       "           -2.76737287e-03],\n",
       "         [  5.33533980e-03,   4.31687419e-03,  -3.30432759e-03,\n",
       "            1.78241667e-02,  -1.14800916e-03,  -1.77139097e-02,\n",
       "            8.69449655e-03,   4.66521717e-03,   9.54412403e-03,\n",
       "            5.01518702e-03]]), matrix([[ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.]]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# W1 = 0.01* np.random.randn(inputLayerSize,hiddenLayerSize);\n",
    "# W2 = 0.01* np.random.randn(hiddenLayerSize,outputLayerSize);\n",
    "# b1 = np.zeros((hiddenLayerSize,1));\n",
    "# b2 = np.zeros((outputLayerSize,1));\n",
    "# print(W1.shape)\n",
    "# print(W2.shape)\n",
    "# print(b1.shape)\n",
    "# print(b2.shape)\n",
    "# print(y_train_mat)\n",
    "# A1, A2, Z1, Z2 = forward_propagate(X_train_mat, W1, W2, b1, b2)\n",
    "# dW1, db1, dW2, db2 = back_propagate(Z1, X_train_mat, y_train_mat, A1, A2, W2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
